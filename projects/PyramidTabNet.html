<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title> PyramidTabNet: Transformer-based Table
    Recognition in Image-based Documents</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="../assets/img/favicon.png" rel="icon">
  <link href="../assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="../assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="../assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="../assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="../assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="../assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="../assets/vendor/venobox/venobox.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../assets/css/main/style.css" rel="stylesheet">

  <!-- =======================================================
    * Template Name: Personal - v2.2.0
    * Template URL: https://bootstrapmade.com/personal-free-resume-bootstrap-template/
    * Author: BootstrapMade.com
    * License: https://bootstrapmade.com/license/
    ======================================================== -->
</head>

<body data-gr-c-s-loaded="true">

  <!-- ======= Portfolio Details ======= -->
  <main id="main">
    <div id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="row">
          <div class="col-lg-12 portfolio-info">
            <br>
            <h2 style="color:#12d640">PyramidTabNet: Transformer-based Table
              Recognition in Image-based Documents</h2>
            <ul>
              <li><strong>Tech Stack</strong>: Machine Learning, Deep Learning, Image Processing, Structure Recognition.</li>
              <li><strong>Github URL</strong>: <a
                  href="https://github.com/muhd-umer/pyramidtabnet" target="_blank">Project
                  Link</a>
              </li>
              <li>
                <strong>Published Paper</strong>: <a
                  href="https://link.springer.com/chapter/10.1007/978-3-031-41734-4_26"
                  target="_blank">Springer Nature Link</a>
                <ul>
                  <li>DOI: https://doi.org/10.1007/978-3-031-41734-4_26</li>
                  <li>Dataset used: ICDAR 2013, ICDAR 2017, ICDAR 2019, Maromot, UNLV, TableBank, PubLay Net</li>
                </ul>
              </li>
            </ul>
            <p>
              Table detection and structure recognition are crucial tasks that have numerous applications in fields such as data extraction, document summarization, and
              information retrieval. Tables play a significant role in presenting data in a structured format, and they are frequently used in a variety of document types, such
              as research papers, reports, and financial statements. The automatic detection
              and recognition of tables and their structures is a complex task that requires the
              integration of several computer vision and pattern recognition techniques.
            </p>
            <p>
              Table detection and structure recognition is an important
              component of document analysis systems. Deep learning-based transformer models have recently demonstrated significant success in various
              computer vision and document analysis tasks. In this paper, we introduce PyramidTabNet (PTN), a method that builds upon Convolutionless Pyramid Vision Transformer to detect tables in document images.
              Furthermore, we present a tabular image generative augmentation technique to effectively train the architecture. The proposed augmentation
              process consists of three steps, namely, clustering, fusion, and patching,
              for the generation of new document images containing tables. Our proposed pipeline demonstrates significant performance improvements for
              table detection on several standard datasets. Additionally, it achieves
              performance comparable to the state-of-the-art methods for structure recognition tasks.

            </p>
            <p>
              This project is associated with TUKL Deep Learning Lab, NUST.
            </p>
          </div>
        </div>

      </div>
    </div><!-- End Portfolio Details -->
  </main><!-- End #main -->

  <!-- Vendor JS Files -->
  <script async="" src="//www.google-analytics.com/analytics.js"></script>
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="../assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="../assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="../assets/vendor/php-email-form/validate.js"></script>
  <script src="../assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="../assets/vendor/counterup/counterup.min.js"></script>
  <script src="../assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="../assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="../assets/vendor/venobox/venobox.min.js"></script>

  <!-- Template Main JS File -->
  <script src="../assets/js/main.js"></script>

</body>

</html>